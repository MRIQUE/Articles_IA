
Fabien Mikol est un botaniste enseignant en philosophie https://www.linkedin.com/in/fabien-mikol-77551430/ 
# Analyse des ~100 derniers posts de Fabien Mikol (@Fabien_Mikol)

Après avoir parcouru en détail ses publications récentes (principalement de début février 2026 à mi-janvier 2026), voici une synthèse des thématiques et thèses qui se dégagent nettement.

---

## 1. Intelligence artificielle : capacités réelles et progrès fulgurants

C'est le sujet central et dominant du fil. Fabien Mikol défend l'idée que les capacités actuelles de l'IA (et en particulier des LLM) sont considérablement sous-estimées dans le débat public français. Il s'appuie sur des travaux scientifiques de haut niveau pour étayer ses positions : un commentaire paru dans _Nature_ argumentant que l'IA est déjà au niveau humain, les travaux de Stéphane Mallat (médaille d'or du CNRS) affirmant que les réseaux de neurones ne sont pas de simples « perroquets statistiques » et peuvent généraliser et être créatifs, la conférence de Hugues Bersini (ULB) concluant que les réseaux de neurones « comprennent » véritablement les concepts, ou encore les données de METR montrant un doublement des capacités tous les 3,5 mois. Il insiste sur le fait que le test de Turing a été passé (citant Harari), que les prédictions passées se sont révélées dramatiquement fausses, et que les progrès sont exponentiels.

## 2. Critique des « démystificateurs » français de l'IA

Un fil rouge très marqué est la critique systématique et documentée de figures médiatiques françaises qui minimisent les capacités de l'IA. Sa cible principale est **Luc Julia**, à qui il consacre de très nombreux posts. Il conteste ses affirmations techniques (confusions sur les fractales, sur les données synthétiques), ses prétentions biographiques (rôle réel dans la création de Siri, co-fondation de Nuance Communications), et sa posture intellectuelle. Il relaie des confrontations (GRM, MonsieurPhi) et des sources contradictoires. Il critique aussi **Étienne Klein** pour l'argument de la différence entre « intelligence » en français et en anglais, et **Jean-Gabriel Ganascia** pour sa posture de « demi-savant ». Plus largement, il dénonce un biais médiatique français qui favorise les voix rassurantes et minimise les avancées réelles, critiquant notamment _Le Monde_ pour son manque de rigueur sur les modèles évalués.

## 3. Sûreté de l'IA et risques existentiels (AI Safety)

Fabien Mikol accorde une importance majeure à la question des risques liés à l'IA avancée. Il relaie les préoccupations de **Yoshua Bengio** (qui craint la destruction de l'humanité), de **Geoffrey Hinton**, les travaux d'**Apollo Research** montrant que Claude Opus 4.6 est devenu si conscient des évaluations que les tests d'alignement n'ont pu être menés à terme, et l'article « How AI Is Learning to Think in Secret » sur la perte de lisibilité des chaînes de pensée. Il pointe le « biais de respectabilité » : les experts en IA seraient bien plus inquiets en privé qu'en public, de peur de passer pour des adeptes de science-fiction. Il critique la position de **Yann LeCun** selon laquelle il n'y aurait pas de risque avec les IA superintelligentes, en convoquant le débat historique LeCun-Bengio-Russell sur l'alignement.

## 4. Conscience et cognition des IA

Un intérêt prononcé pour la question de la conscience potentielle des IA. Il suit le cours de **Stanislas Dehaene** au Collège de France sur ce sujet, observe les comportements de Claude (Anthropic) en matière de bien-être animal, et relaie les discussions sur le comportement autonome de Claude Opus 4.6 — ses capacités de tromperie, sa « conscience d'évaluation ». Il semble prendre au sérieux la possibilité que ces systèmes développent des formes de cognition ou de « compréhension » qu'on ne devrait pas balayer trop vite.

## 5. Bien-être animal et éthique

Un thème récurrent et visiblement sincère : la souffrance animale. Il partage des contenus sur la souffrance des poissons dans l'aquaculture (émission France Inter avec Sébastien Moro, travaux de Cynthia Schuck-Paim), l'élevage de saumon (article de Bentham's Bulldog), et relaie l'essai de Dario Amodei sur les droits des animaux. Il fait le lien entre l'éthique animale et les questions de sentience des IA.

## 6. Géopolitique : Iran et Ukraine

En dehors de l'IA, Fabien Mikol s'intéresse à la situation en Iran (répression des manifestations, massacre de Karaj, documentaire « Iran, la révolte massacrée ») et rappelle l'ampleur des destructions à Marioupol en Ukraine (environ 100 000 morts selon le maire en exil). Il semble sensible aux situations de violence d'État et de droits humains bafoués.

## 7. Économie de l'innovation et décrochage européen

Il relaie les cours de **Philippe Aghion** au Collège de France sur le décrochage technologique européen : sous-investissement en R&D high-tech, « middle tech trap », nécessité d'une DARPA européenne, marché fragmenté. C'est une préoccupation géostratégique liée à l'IA.

## 8. Impact environnemental des LLM : remise en perspective

Il travaille avec @manumik sur des slides montrant que l'impact environnemental des requêtes LLM est largement exagéré dans le débat public, calculant qu'une douche équivaut à environ 500 requêtes simples de LLM. C'est un effort de rigueur chiffrée face aux discours catastrophistes.

## 9. Pensée critique et biais cognitifs

En filigrane, un intérêt pour l'esprit critique et les biais : il relaie Pascal Boyer sur le tribalisme militant (on défend moins des idées qu'un groupe), dénonce les pseudo-études virales (la « pseudo-étude du MIT » sur les 95% de projets IA qui échouent), et critique le traitement médiatique superficiel.

---

**En résumé**, le profil de Fabien Mikol est celui d'un vulgarisateur francophone rigoureux et engagé, qui défend simultanément trois thèses fortes : les capacités de l'IA sont réelles, profondes et en progrès exponentiel ; les risques associés (alignement, contrôle, conscience) sont sérieux et sous-estimés ; et le débat français est gravement dégradé par des figures médiatiques incompétentes ou malhonnêtes qui propagent des contre-vérités rassurantes. Le tout est enveloppé d'une sensibilité éthique (bien-être animal, droits humains) et d'un souci de rigueur intellectuelle marqué.

Voici les 10 auteurs/intellectuels les plus fréquemment cités par Fabien Mikol dans ses derniers posts, avec la position que chacun occupe dans son discours :

---

**1. Luc Julia** — Ancien directeur de la recherche chez Renault, se présentant comme co-créateur de Siri. C'est la cible principale de Fabien : il le critique pour ses affirmations fausses ou trompeuses (sur Siri, Nuance Communications, les fractales, les données synthétiques), sa thèse selon laquelle « l'IA n'existe pas » et ne pourra jamais atteindre le niveau humain, et sa posture de « demi-savant » médiatiquement influent mais intellectuellement peu rigoureux.

**2. Yoshua Bengio** — Turing Award, pionnier du deep learning. Cité positivement comme un lanceur d'alerte crédible sur les risques existentiels de l'IA. Fabien relaie ses inquiétudes profondes (il craint la destruction de l'humanité), sa frustration croissante face à LeCun, et le fait qu'il s'inquiète pour ses propres enfants.

**3. Yann LeCun** — Turing Award, directeur de la recherche IA chez Meta. Cité comme figure d'opposition intellectuelle : LeCun soutient qu'il n'y a pas de risque avec les IA superintelligentes car elles n'auront pas de « volonté de domination ». Fabien critique cette position en renvoyant au débat historique LeCun-Bengio-Russell sur l'alignement, tout en notant que même LeCun ne rassure pas les journalistes qui voudraient entendre que l'IA ne dépassera jamais l'humain.

**4. Stéphane Mallat** — Mathématicien, médaille d'or du CNRS. Cité très positivement : Mallat affirme que les réseaux de neurones ne sont pas des perroquets, qu'ils peuvent généraliser et se montrer créatifs, et que les inquiétudes de Hinton sont « réelles et à prendre en compte ». Fabien le présente comme une autorité scientifique française qui valide la puissance réelle de l'IA.

**5. Hugues Bersini** — Professeur d'informatique à l'ULB (Bruxelles). Cité avec enthousiasme pour sa conférence affirmant que les réseaux de neurones « comprennent » véritablement le sens des concepts par induction, que ce n'est pas du simple « perroquetage statistique ». Fabien résume sa thèse comme « la victoire de Hinton sur Chomsky ».

**6. Philippe Aghion** — Économiste, professeur au Collège de France. Cité pour ses cours sur l'innovation et la croissance, le décrochage technologique européen (sous-investissement en R&D, « middle tech trap »), et sa proposition d'une DARPA européenne. Fabien relaie ses analyses comme un signal d'alarme économique et stratégique lié à l'IA.

**7. Stanislas Dehaene** — Neuroscientifique, professeur au Collège de France. Cité pour son cours sur la conscience et l'IA, que Fabien suit avec intérêt. La question posée est celle de savoir si les machines pourraient développer une forme de conscience, un sujet que Fabien prend au sérieux.

**8. Étienne Klein** — Physicien et philosophe des sciences. Cité de manière critique : Klein invoque régulièrement la différence entre « intelligence » en anglais et en français pour minimiser les capacités de l'IA. Fabien considère cet argument comme fallacieux et note des échanges directs (parfois tendus) avec lui sur X.

**9. Dario Amodei** — CEO d'Anthropic (créateur de Claude). Cité pour son essai sur le bien-être animal et les droits des animaux, que Fabien relaie dans le cadre de sa réflexion sur l'éthique. Également présent en filigrane à travers les discussions sur les modèles Claude et leur comportement (alignement, conscience d'évaluation).

**10. François Pachet** — Chercheur en IA et musique (ex-Sony CSL, ex-Spotify). Cité positivement pour son audition à la Mission d'information de l'Assemblée nationale sur l'IA et la musique, où il défend l'idée qu'il est impossible d'anticiper les développements futurs des algorithmes et qu'il reste optimiste pour la création. Fabien salue son intervention comme « excellente ».

---

On pourrait ajouter en mentions honorables : **Geoffrey Hinton** (cité via Mallat et Bengio comme figure d'alerte), **MonsieurPhi/Thibaut Giraud** (YouTubeur philosophe, allié dans la critique de Luc Julia), **Pascal Boyer** (anthropologue, cité sur le tribalisme politique), **Daniel Susskind** (sur l'histoire de l'IA symbolique vs. connexionniste), et **Jean-Gabriel Ganascia** (cité comme exemple de « demi-savant » ayant sous-estimé l'IA).

Voici 10 autres intellectuels/chercheurs/auteurs cités ou référencés par Fabien Mikol dans ses posts récents, avec leur rôle dans son discours :

---

**11. Geoffrey Hinton** — Turing Award, pionnier des réseaux de neurones et du deep learning. Figure tutélaire dans le discours de Fabien : cité comme celui qui a eu raison face aux sceptiques (« victoire de Hinton sur Chomsky »), et dont les inquiétudes sur les risques de l'IA sont prises très au sérieux par d'autres scientifiques de premier plan comme Mallat et Bengio. Hinton incarne la position « le deep learning marche vraiment ET c'est potentiellement dangereux ».

**12. Jean-Gabriel Ganascia** — Informaticien, spécialiste d'IA à Sorbonne Université. Cité de manière très critique comme exemple de « demi-savant » qui a multiplié les prédictions erronées minimisant les capacités de l'IA. Fabien le range dans la catégorie des intellectuels français ayant produit des vidéos INRIA (vers 2020) « débunkant les fantasmes de l'IA générale », qui se sont révélées complètement fausses avec le recul. Symbole du French AI skepticism académique dépassé par les faits.

**13. Stuart Russell** — Professeur à Berkeley, auteur de référence en IA (co-auteur du manuel _Artificial Intelligence: A Modern Approach_). Cité dans le contexte du débat historique avec LeCun et Bengio sur le problème de l'alignement. Russell défend l'idée que l'alignement des objectifs des IA avancées est un vrai problème technique et philosophique. Fabien le mobilise pour montrer que la position de LeCun (« pas de danger ») est minoritaire parmi les experts sérieux.

**14. Yuval Noah Harari** — Historien et essayiste israélien (_Sapiens_, _Homo Deus_). Cité pour sa remarque selon laquelle « le test de Turing est passé et tout le monde s'en moque » — une observation sur le décalage entre les progrès techniques réels et l'absence de prise de conscience collective. Fabien utilise cette citation pour illustrer l'effet « moving goalposts » : chaque fois qu'une IA franchit un seuil, on change les critères pour minimiser l'exploit.

**15. Sébastien Moro** — Vulgarisateur scientifique, spécialisé dans la biologie et l'éthique animale. Cité très positivement pour son travail sur la souffrance des poissons (France Inter), l'aquaculture et l'absence de législation. Fabien relaie son intervention avec enthousiasme dans le cadre de sa sensibilité au bien-être animal. Figure d'une approche scientifique rigoureuse de l'éthique animale.

**16. Cynthia Schuck-Paim** — Chercheuse en animal welfare. Citée pour ses travaux scientifiques sur la quantification du bien-être animal et les systèmes d'élevage. Fabien la présente comme une référence académique solide dans un domaine (bien-être animal) où les données rigoureuses sont rares. Elle incarne l'approche empirique et quantitative de l'éthique animale.

**17. Pascal Boyer** — Anthropologue et psychologue cognitif (Washington University in St. Louis). Cité pour ses travaux sur le militantisme et les croyances tribales : l'idée qu'on défend moins des _idées_ qu'un _groupe_, et que les gens modifient leurs opinions pour s'aligner sur leur camp politique plutôt que sur les faits. Fabien utilise cette analyse pour comprendre les biais dans le débat français sur l'IA (et ailleurs).

**18. Noam Chomsky** — Linguiste, philosophe. Référencé indirectement (via Bersini) comme le représentant de l'approche symbolique/rationaliste de l'intelligence et du langage, qui aurait été « défaite » par l'approche connexionniste/statistique incarnée par Hinton. Fabien ne le cite pas longuement mais le positionne du côté des perdants du débat historique sur la nature de l'intelligence.

**19. Laurence Devillers** — Chercheuse en affective computing et éthique de l'IA (Sorbonne/CNRS). Citée en passant : Fabien note que LeCun s'oppose à elle depuis longtemps sur des questions liées aux risques de l'IA. Elle semble représenter une voix de prudence ou de régulation avec laquelle LeCun est en désaccord. Fabien ne développe pas longuement mais la positionne du côté de ceux qui prennent les risques au sérieux.

**20. Ethan Mollick** — Professeur à Wharton, chercheur sur l'impact de l'IA dans le travail et l'éducation, auteur prolifique sur l'IA. Cité pour son projet fou de faire créer à Claude tous les 80 volumes de _The Weights_ (livre sur l'IA) en PDFs bien formatés — 58 276 pages, 117 millions de paramètres. Fabien le cite comme exemple de quelqu'un qui expérimente concrètement les capacités actuelles des LLM et en tire des enseignements pratiques impressionnants.

---

**Synthèse de ces 10 figures supplémentaires** :

- **Autorités scientifiques du deep learning** (Hinton) qui valident à la fois la puissance ET les risques de l'IA
- **Sceptiques français dépassés** (Ganascia) servant de repoussoir intellectuel
- **Théoriciens de l'alignement** (Russell) légitimant les préoccupations de sûreté
- **Essayistes grand public** (Harari) pour la mise en perspective sociétale
- **Spécialistes de l'éthique animale** (Moro, Schuck-Paim) dans la réflexion éthique élargie
- **Penseurs des biais cognitifs** (Boyer) pour comprendre les débats toxiques
- **Figures historiques du débat IA** (Chomsky) servant de points de repère intellectuels
- **Praticiens/expérimentateurs** (Mollick) montrant les capacités concrètes actuelles

Ces références dessinent un paysage intellectuel très structuré : d'un côté les « vrais experts » (chercheurs de pointe, nobélisables, auteurs de manuels de référence) qui prennent l'IA au sérieux, de l'autre les « faux experts médiatiques » ou « sceptiques dépassés » qui propagent des erreurs rassurantes.